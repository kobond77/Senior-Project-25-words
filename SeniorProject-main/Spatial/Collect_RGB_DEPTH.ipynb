{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.8)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.18.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import cv2\n",
    "import depthai as dai\n",
    "from calc import HostSpatialsCalc\n",
    "from utility import *\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "\n",
    "# Properties\n",
    "queueNames = []\n",
    "downscaleColor = True\n",
    "fps = 30\n",
    "monoResolution = dai.MonoCameraProperties.SensorResolution.THE_720_P\n",
    "\n",
    "#--- RGB Camera ---#\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "camRgb.setFps(fps)\n",
    "if downscaleColor: camRgb.setIspScale(2, 3)\n",
    "# For now, RGB needs fixed focus to properly align with depth.\n",
    "# This value was used during calibration\n",
    "camRgb.initialControl.setManualFocus(130)\n",
    "\n",
    "# Get RGB Output\n",
    "rgbOut = pipeline.create(dai.node.XLinkOut)\n",
    "rgbOut.setStreamName(\"rgb\")\n",
    "camRgb.isp.link(rgbOut.input)\n",
    "queueNames.append(\"rgb\")\n",
    "\n",
    "#--- Depth Camera ---#\n",
    "\n",
    "monoLeft = pipeline.create(dai.node.MonoCamera)\n",
    "monoRight = pipeline.create(dai.node.MonoCamera)\n",
    "stereo = pipeline.create(dai.node.StereoDepth)\n",
    "\n",
    "monoLeft.setResolution(monoResolution)\n",
    "monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "monoRight.setResolution(monoResolution)\n",
    "monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "stereo.initialConfig.setConfidenceThreshold(255)\n",
    "stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)\n",
    "# LR-check is required for depth alignment\n",
    "stereo.setLeftRightCheck(True)\n",
    "stereo.setDepthAlign(dai.CameraBoardSocket.RGB)\n",
    "\n",
    "# Get Depth Ouput\n",
    "monoLeft.out.link(stereo.left)\n",
    "monoRight.out.link(stereo.right)\n",
    "\n",
    "DepthOut = pipeline.create(dai.node.XLinkOut)\n",
    "DepthOut.setStreamName(\"depth\")\n",
    "queueNames.append(\"depth\")\n",
    "stereo.depth.link(DepthOut.input)\n",
    "\n",
    "dispOut = pipeline.create(dai.node.XLinkOut)\n",
    "dispOut.setStreamName(\"disp\")\n",
    "queueNames.append(\"disp\")\n",
    "stereo.disparity.link(dispOut.input)\n",
    "\n",
    "# Hand skeleton\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "hands = mp_hands.Hands( \n",
    "                        min_detection_confidence=0.5,\n",
    "                        min_tracking_confidence=0.5)\n",
    "# Pose skeleton\n",
    "pose  = mp_pose.Pose( static_image_mode=True,\n",
    "                      model_complexity=1,\n",
    "                      enable_segmentation=True,\n",
    "                      min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pose_tracking_full_body_landmarks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hand_landmarks.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ai\\\\Documents\\\\GitHub\\\\SeniorProject-Finn-new\\\\SeniorProject-main\\\\Spatial'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_word(word = None) :\n",
    "    DATA_PATH = os.path.join('Collected_Data_With_Face') \n",
    "    DATA_RGB_PATH =os.path.join(DATA_PATH,word,'RGB')\n",
    "    DATA_RGB_FAKE_PATH =os.path.join(DATA_PATH,word,'RGB_FAKE_Z')\n",
    "    DATA_NORM_DEPTH_PATH =os.path.join(DATA_PATH,word,'NORM_DEPTH')\n",
    "    DATA_WORLD_PATH =os.path.join(DATA_PATH,word,'WORLD_DEPTH')\n",
    "    rgb_exist = os.path.exists(DATA_RGB_PATH)\n",
    "    rgb_fake_exist = os.path.exists(DATA_RGB_FAKE_PATH)\n",
    "    normimg_exist = os.path.exists(DATA_NORM_DEPTH_PATH)\n",
    "    world_exist = os.path.exists(DATA_WORLD_PATH)\n",
    "    print(f\"You are going to collect '{word}'\")\n",
    "    if not rgb_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_RGB_PATH)\n",
    "        print(\"The new directory for image data is created !!!!\")\n",
    "    if not rgb_fake_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_RGB_FAKE_PATH)\n",
    "        print(\"The new directory for image fake z data is created !!!!\")\n",
    "    if not normimg_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_NORM_DEPTH_PATH)\n",
    "        print(\"The new directory for normalized image data is created !!!!\")\n",
    "    if not world_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_WORLD_PATH)\n",
    "        print(\"The new directory for world data  is created !!!!\")\n",
    "    return word, DATA_RGB_PATH ,DATA_RGB_FAKE_PATH, DATA_NORM_DEPTH_PATH, DATA_WORLD_PATH\n",
    "    \n",
    "def get_hand_data(index,hand,hand_results) : \n",
    "    points = np.zeros((21,3))\n",
    "    norm_points = np.zeros((21,3))\n",
    "    Label = None\n",
    "    for idx,classification in enumerate(hand_results.multi_handedness) : \n",
    "        if classification.classification[0].index == index :\n",
    "            Label = classification.classification[0].label\n",
    "        for i in range(21) : \n",
    "            points[i,:] = np.multiply(np.array((hand.landmark[i].x, hand.landmark[i].y,0)),[1280,720,1])\n",
    "            norm_points[i,:] = np.array((hand.landmark[i].x, hand.landmark[i].y,hand.landmark[i].z))\n",
    "    return Label,points,norm_points\n",
    "\n",
    "\n",
    "def get_pose_data(pose_results) :\n",
    "    points = np.zeros((13,3))  \n",
    "    norm_points = np.zeros((13,3))\n",
    "    pose_landmark = pose_results.pose_landmarks.landmark[0:13] \n",
    "    for i in range(13) : \n",
    "        points[i,:] = np.multiply(np.array((pose_landmark[i].x, pose_landmark[i].y,0)),[1280,720,1])\n",
    "        norm_points[i,:] = np.array((pose_landmark[i].x, pose_landmark[i].y,pose_landmark[i].z))\n",
    "    return points,norm_points\n",
    "\n",
    "def get_spatial(depthFrame,x,y) : \n",
    "    spatials, centroid = hostSpatials.calc_spatials(depthFrame, (x,y))\n",
    "    return spatials,centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to collect 'so'\n",
      "The new directory for image data is created !!!!\n",
      "The new directory for image fake z data is created !!!!\n",
      "The new directory for normalized image data is created !!!!\n",
      "The new directory for world data  is created !!!!\n"
     ]
    }
   ],
   "source": [
    "# Collect word config\n",
    "word, DATA_RGB_PATH ,DATA_RGB_FAKE_PATH, DATA_NORM_DEPTH_PATH, DATA_WORLD_PATH = Collect_word(word = 'so')\n",
    "no_sequences = 60\n",
    "sequence_length = 30 \n",
    "#have alt2\n",
    "#yes alt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MxId: 14442C1071FD60D700\n",
      "USB speed: UsbSpeed.SUPER\n",
      "Connected cameras: [<CameraBoardSocket.RGB: 0>, <CameraBoardSocket.LEFT: 1>, <CameraBoardSocket.RIGHT: 2>]\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n",
      "(30, 55, 3)\n"
     ]
    }
   ],
   "source": [
    "# Connect to device and start pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Output queue will be used to get the depth frames from the outputs defined above\n",
    "    # Print Myriad X Id (MxID), USB speed, and available cameras on the device\n",
    "    print('MxId:',device.getDeviceInfo().getMxId())\n",
    "    print('USB speed:',device.getUsbSpeed())\n",
    "    print('Connected cameras:',device.getConnectedCameras())\n",
    "    \n",
    "    # Define output Queue\n",
    "    rgbQueue = device.getOutputQueue(name = \"rgb\")\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\")\n",
    "    dispQueue = device.getOutputQueue(name=\"disp\")\n",
    "    # Name windows\n",
    "    rgbWindowName = \"rgb\"\n",
    "    depthWindowName = \"depth\"\n",
    "    cv2.namedWindow(rgbWindowName)\n",
    "    cv2.namedWindow(depthWindowName)\n",
    "\n",
    "    text = TextHelper()\n",
    "    hostSpatials = HostSpatialsCalc(device)\n",
    "    delta = 10\n",
    "    hostSpatials.setDeltaRoi(delta)        \n",
    "    DisplayRect = False            \n",
    "                                                        \n",
    "    previousTime = 0\n",
    "    currentTime = 0\n",
    "    Break = False\n",
    "    \n",
    "    # Left(0->20),Right(21->41),Face(42->54)\n",
    "   \n",
    "    for seqeunce in range (no_sequences) :\n",
    "        RGB_sequence        = []\n",
    "        RGB_fake_sequence   = []\n",
    "        norm_image_sequence = []\n",
    "        world_sequence      = []\n",
    "        frame = 0\n",
    "        if Break : break\n",
    "        while True:\n",
    "            latestPacket = {}\n",
    "            latestPacket[\"rgb\"] = None\n",
    "            latestPacket[\"disp\"] = None\n",
    "            latestPacket['depth'] = None\n",
    "            queueEvents = device.getQueueEvents(('rgb','disp','depth'))\n",
    "            for queueName in queueEvents :\n",
    "                packets = device.getOutputQueue(queueName).tryGetAll()\n",
    "                if len(packets) > 0 :\n",
    "                    latestPacket[queueName] = packets[-1]\n",
    "            # Left(0->20),Right(21->41),Face(42->54)\n",
    "            data_image          = np.zeros((55,3)) # Contain x y with 1280x720 resolution and z in metre.\n",
    "            data_z_image        = np.zeros((55,3))\n",
    "            data_norm_image     = np.zeros((55,3)) # Contain normalized x y in range (0,1) and z in metre.\n",
    "            data_world          = np.zeros((55,3)) # Contain x y and z in metre.\n",
    "            #---- RGB ----#\n",
    "            if latestPacket[\"rgb\"] is not None:\n",
    "                rgbFrame = latestPacket[\"rgb\"].getCvFrame()\n",
    "                # Pre-process\n",
    "                rgbFrame.flags.writeable = False\n",
    "                rgbFrame = cv2.cvtColor(rgbFrame, cv2.COLOR_BGR2RGB)\n",
    "                # Note that handedness is determined assuming the input image is mirrored, \n",
    "                # i.e., taken with a front-facing/selfie camera with images flipped horizontally. \n",
    "                # If it is not the case, please swap the handedness output in the application.\n",
    "                rgbFrame = cv2.flip(rgbFrame, 1)\n",
    "                hand_results = hands.process(rgbFrame)\n",
    "                pose_results = pose.process(rgbFrame)\n",
    "                # Draw the hand annotations on the image.\n",
    "                rgbFrame.flags.writeable = True\n",
    "                rgbFrame = cv2.cvtColor(rgbFrame, cv2.COLOR_RGB2BGR)\n",
    "                cv2.putText(rgbFrame,f'Collecting frames for {word},Video Number {seqeunce}',(15,30)\n",
    "                            , cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                cv2.putText(rgbFrame,f'frames: {frame}',(15,80) , cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                #--- Depth ---#\n",
    "                if latestPacket[\"depth\"] is not None:\n",
    "                    depthFrame = latestPacket[\"depth\"].getCvFrame()\n",
    "                    depthFrame = cv2.flip(depthFrame, 1)\n",
    "                    # Get disparity frame for nicer depth visualization\n",
    "                    if latestPacket[\"disp\"] is not None:\n",
    "                        dispFrame = latestPacket[\"disp\"].getFrame()\n",
    "                        maxDisparity = stereo.initialConfig.getMaxDisparity()\n",
    "\n",
    "                    \n",
    "                        dispFrame = (dispFrame * (255 / maxDisparity)).astype(np.uint8)\n",
    "                        dispFrame = cv2.applyColorMap(dispFrame, cv2.COLORMAP_JET)\n",
    "                        dispFrame = np.ascontiguousarray(dispFrame)\n",
    "                        dispFrame = cv2.flip(dispFrame, 1)\n",
    "                        if hand_results.multi_hand_landmarks:\n",
    "                            for index, hand in enumerate(hand_results.multi_hand_landmarks) :\n",
    "                                # Draw hand on RGB Frame\n",
    "                                mp_drawing.draw_landmarks(  rgbFrame,\n",
    "                                                            hand,\n",
    "                                                            mp_hands.HAND_CONNECTIONS,\n",
    "                                                            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                                            mp_drawing_styles.get_default_hand_connections_style())\n",
    "                                # Draw hand on Depth Frame\n",
    "                                mp_drawing.draw_landmarks(  dispFrame,\n",
    "                                                            hand,\n",
    "                                                            mp_hands.HAND_CONNECTIONS,\n",
    "                                                            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                                            mp_drawing_styles.get_default_hand_connections_style())\n",
    "                                # get points of each hand\n",
    "                                Label,hand_points,hand_norm_points = get_hand_data(index,hand,hand_results)\n",
    "                                if Label == 'Left' : \n",
    "                                    data_image[0:21,:] = hand_points\n",
    "                                    data_norm_image[0:21,:] = hand_norm_points\n",
    "                                else :\n",
    "                                    data_image[21:42,:] = hand_points\n",
    "                                    data_norm_image[21:42,:] = hand_norm_points\n",
    "                        if pose_results.pose_landmarks : \n",
    "                            # Draw Pose on RGB Frame\n",
    "                            mp_drawing.draw_landmarks(  rgbFrame,\n",
    "                                                        pose_results.pose_landmarks,\n",
    "                                                        mp_pose.POSE_CONNECTIONS,\n",
    "                                                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                            # Draw Pose on Depth Frame\n",
    "                            mp_drawing.draw_landmarks(  rgbFrame,\n",
    "                                                        pose_results.pose_landmarks,\n",
    "                                                        mp_pose.POSE_CONNECTIONS,\n",
    "                                                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                            # get points of pose\n",
    "                            pose_points,pose_norm_points = get_pose_data(pose_results)\n",
    "                            data_image[42:55,:] = pose_points\n",
    "                            data_norm_image[42:55,:] = pose_norm_points\n",
    "                            data_z_image  = data_norm_image.copy()\n",
    "                        for i in range(55) : \n",
    "                            x = int(data_image[i,0])\n",
    "                            y = int(data_image[i,1]) \n",
    "                            if (x != 0) and (y != 0) : \n",
    "                                spatials, centroid = get_spatial(depthFrame,x,y)\n",
    "                                if not math.isnan(float(spatials['x']))  : data_world[i,0] = spatials['x']/1000\n",
    "                                if not math.isnan(float(spatials['y']))  : data_world[i,1] = spatials['y']/1000\n",
    "                                if not math.isnan(float(spatials['z']))  : \n",
    "                                    data_world[i,2]    = spatials['z']/1000\n",
    "                                    data_norm_image[i,2] = spatials['z']/1000\n",
    "                                    data_image[i,2]      = spatials['z']/1000\n",
    "                            if DisplayRect : \n",
    "                                text.rectangle(dispFrame, (x-delta, y-delta), (x+delta, y+delta))\n",
    "                        #print(data_image)\n",
    "                        RGB_sequence.append(data_image)\n",
    "                        RGB_fake_sequence.append(data_z_image)\n",
    "                        norm_image_sequence.append(data_norm_image)\n",
    "                        world_sequence.append(data_world)\n",
    "\n",
    "                         # Display the resulting image\n",
    "                        cv2.imshow(rgbWindowName, rgbFrame)\n",
    "                        #cv2.imshow(depthWindowName, dispFrame)\n",
    "                        rgbFrame = None\n",
    "                        depthFrame = None\n",
    "                        dispFrame = None\n",
    "                        frame += 1\n",
    "                        if len(RGB_sequence) == sequence_length :\n",
    "                            print(np.array(RGB_sequence).shape)\n",
    "                            NP_DATA_RGB_PATH = os.path.join(DATA_RGB_PATH,f\"{word+'_RGB'}_{seqeunce}\")\n",
    "                            NP_DATA_RGB_FAKE_PATH = os.path.join(DATA_RGB_FAKE_PATH,f\"{word+'_RGB_FAKE_Z'}_{seqeunce}\")\n",
    "                            NP_DATA_NORM_DEPTH_PATH = os.path.join(DATA_NORM_DEPTH_PATH,f\"{word+'_norm_depth'}_{seqeunce}\")\n",
    "                            NP_DATA_WORLD_PATH = os.path.join(DATA_WORLD_PATH,f\"{word+'_world'}_{seqeunce}\")\n",
    "                            np.save(NP_DATA_RGB_PATH, np.array(RGB_sequence))\n",
    "                            np.save(NP_DATA_RGB_FAKE_PATH, np.array(RGB_fake_sequence))\n",
    "                            np.save(NP_DATA_NORM_DEPTH_PATH, np.array(norm_image_sequence))\n",
    "                            np.save(NP_DATA_WORLD_PATH, np.array(world_sequence))\n",
    "                            cv2.waitKey(500)\n",
    "                            cv2.destroyAllWindows()\n",
    "                            break \n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord('q'):\n",
    "                    Break = True\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b9221c9fa0c804214309051805ad5497afac26eb3bf5b138d56a6216387e02b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
