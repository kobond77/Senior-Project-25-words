{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\programdata\\anaconda3\\lib\\site-packages (21.3)\n",
      "Collecting pip\n",
      "  Using cached pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-22.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "  WARNING: The scripts pip.exe, pip3.8.exe and pip3.exe are installed in 'C:\\Users\\Ai\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.18.1)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (0.14.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import cv2\n",
    "import depthai as dai\n",
    "from calc import HostSpatialsCalc\n",
    "from utility import *\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'model_complexity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1db4b8e8ec75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mmp_hands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mmp_pose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m hands = mp_hands.Hands( model_complexity=0,\n\u001b[0m\u001b[0;32m     64\u001b[0m                         \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         min_tracking_confidence=0.5)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'model_complexity'"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "\n",
    "# Properties\n",
    "queueNames = []\n",
    "downscaleColor = True\n",
    "fps = 30\n",
    "monoResolution = dai.MonoCameraProperties.SensorResolution.THE_720_P\n",
    "\n",
    "#--- RGB Camera ---#\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "camRgb.setFps(fps)\n",
    "if downscaleColor: camRgb.setIspScale(2, 3)\n",
    "# For now, RGB needs fixed focus to properly align with depth.\n",
    "# This value was used during calibration\n",
    "camRgb.initialControl.setManualFocus(130)\n",
    "\n",
    "# Get RGB Output\n",
    "rgbOut = pipeline.create(dai.node.XLinkOut)\n",
    "rgbOut.setStreamName(\"rgb\")\n",
    "camRgb.isp.link(rgbOut.input)\n",
    "queueNames.append(\"rgb\")\n",
    "\n",
    "#--- Depth Camera ---#\n",
    "\n",
    "monoLeft = pipeline.create(dai.node.MonoCamera)\n",
    "monoRight = pipeline.create(dai.node.MonoCamera)\n",
    "stereo = pipeline.create(dai.node.StereoDepth)\n",
    "\n",
    "monoLeft.setResolution(monoResolution)\n",
    "monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "monoRight.setResolution(monoResolution)\n",
    "monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "stereo.initialConfig.setConfidenceThreshold(255)\n",
    "stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)\n",
    "# LR-check is required for depth alignment\n",
    "stereo.setLeftRightCheck(True)\n",
    "stereo.setDepthAlign(dai.CameraBoardSocket.RGB)\n",
    "\n",
    "# Get Depth Ouput\n",
    "monoLeft.out.link(stereo.left)\n",
    "monoRight.out.link(stereo.right)\n",
    "\n",
    "DepthOut = pipeline.create(dai.node.XLinkOut)\n",
    "DepthOut.setStreamName(\"depth\")\n",
    "queueNames.append(\"depth\")\n",
    "stereo.depth.link(DepthOut.input)\n",
    "\n",
    "dispOut = pipeline.create(dai.node.XLinkOut)\n",
    "dispOut.setStreamName(\"disp\")\n",
    "queueNames.append(\"disp\")\n",
    "stereo.disparity.link(dispOut.input)\n",
    "\n",
    "# Hand skeleton\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "hands = mp_hands.Hands( model_complexity=0,\n",
    "                        min_detection_confidence=0.5,\n",
    "                        min_tracking_confidence=0.5)\n",
    "# Pose skeleton\n",
    "pose  = mp_pose.Pose( static_image_mode=True,\n",
    "                      model_complexity=2,\n",
    "                      enable_segmentation=True,\n",
    "                      min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pose_tracking_full_body_landmarks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hand_landmarks.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_data(index,hand,hand_results) : \n",
    "    points = np.zeros((21,3))\n",
    "    norm_points = np.zeros((21,3))\n",
    "    Label = None\n",
    "    for idx,classification in enumerate(hand_results.multi_handedness) : \n",
    "        if classification.classification[0].index == index :\n",
    "            Label = classification.classification[0].label\n",
    "        for i in range(21) : \n",
    "            points[i,:] = np.multiply(np.array((hand.landmark[i].x, hand.landmark[i].y,0)),[1280,720,1])\n",
    "            norm_points[i:] = np.array((hand.landmark[i].x, hand.landmark[i].y,0))\n",
    "    return Label,points,norm_points\n",
    "\n",
    "\n",
    "def get_pose_data(pose_results) :\n",
    "    points = np.zeros((13,3))  \n",
    "    norm_points = np.zeros((13,3))\n",
    "    pose_landmark = pose_results.pose_landmarks.landmark[0:13] \n",
    "    for i in range(13) : \n",
    "        points[i,:] = np.multiply(np.array((pose_landmark[i].x, pose_landmark[i].y,0)),[1280,720,1])\n",
    "        norm_points[i,:] = np.array((pose_landmark[i].x, pose_landmark[i].y,0))\n",
    "    return points,norm_points\n",
    "\n",
    "def get_spatial(depthFrame,x,y) : \n",
    "    spatials, centroid = hostSpatials.calc_spatials(depthFrame, (x,y))\n",
    "    return spatials,centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_word(word = None) :\n",
    "    DATA_PATH = os.path.join('Collected_Data_With_Face') \n",
    "    DATA_IMAGE_PATH =os.path.join(DATA_PATH,word,'data_image')\n",
    "    DATA_NORM_IMAGE_PATH =os.path.join(DATA_PATH,word,'data_norm_image')\n",
    "    DATA_WORLD_PATH =os.path.join(DATA_PATH,word,'data_world_image')\n",
    "    img_exist = os.path.exists(DATA_IMAGE_PATH)\n",
    "    normimg_exist = os.path.exists(DATA_NORM_IMAGE_PATH)\n",
    "    world_exist = os.path.exists(DATA_WORLD_PATH)\n",
    "    print(f\"You are going to collect '{word}'\")\n",
    "    if not img_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_IMAGE_PATH)\n",
    "        print(\"The new directory for image data is created !!!!\")\n",
    "    if not normimg_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_NORM_IMAGE_PATH)\n",
    "        print(\"The new directory for normalized image data is created !!!!\")\n",
    "    if not world_exist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(DATA_WORLD_PATH)\n",
    "        print(\"The new directory for world data  is created !!!!\")\n",
    "    return word, DATA_IMAGE_PATH , DATA_NORM_IMAGE_PATH, DATA_WORLD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MxId: 14442C1071FD60D700\n",
      "USB speed: UsbSpeed.SUPER\n",
      "Connected cameras: [<CameraBoardSocket.RGB: 0>, <CameraBoardSocket.LEFT: 1>, <CameraBoardSocket.RIGHT: 2>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\senior\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "F:\\Anaconda\\envs\\senior\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Connect to device and start pipeline\n",
    "Show_depth = True\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Output queue will be used to get the depth frames from the outputs defined above\n",
    "    # Print Myriad X Id (MxID), USB speed, and available cameras on the device\n",
    "    print('MxId:',device.getDeviceInfo().getMxId())\n",
    "    print('USB speed:',device.getUsbSpeed())\n",
    "    print('Connected cameras:',device.getConnectedCameras())\n",
    "    \n",
    "    # Define output Queue\n",
    "    rgbQueue = device.getOutputQueue(name = \"rgb\")\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\")\n",
    "    dispQueue = device.getOutputQueue(name=\"disp\")\n",
    "    # Name windows\n",
    "    rgbWindowName = \"rgb\"\n",
    "    depthWindowName = \"depth\"\n",
    "    cv2.namedWindow(rgbWindowName)\n",
    "    cv2.namedWindow(depthWindowName)\n",
    "\n",
    "    text = TextHelper()\n",
    "    hostSpatials = HostSpatialsCalc(device)\n",
    "    delta = 10\n",
    "    hostSpatials.setDeltaRoi(delta)        \n",
    "    DisplayRect = False            \n",
    "                                                        \n",
    "    previousTime = 0\n",
    "    currentTime = 0\n",
    "\n",
    "    image_sequence      = []\n",
    "    norm_image_sequence = []\n",
    "    world_sequence      = []\n",
    "    # Left(0->20),Right(21->41),Face(42->54)\n",
    "    # data_image          = {'Left': np.zeros((21,3)),'Right': np.zeros((21,3))}\n",
    "    # data_norm_image     = {'Left': np.zeros((21,3)),'Right': np.zeros((21,3))}\n",
    "    # data_world          = {'Left': np.zeros((21,3)),'Right': np.zeros((21,3))}\n",
    "\n",
    "    while True:\n",
    "        latestPacket = {}\n",
    "        latestPacket[\"rgb\"] = None\n",
    "        latestPacket[\"disp\"] = None\n",
    "        latestPacket['depth'] = None\n",
    "        queueEvents = device.getQueueEvents(('rgb','disp','depth'))\n",
    "        for queueName in queueEvents :\n",
    "            packets = device.getOutputQueue(queueName).tryGetAll()\n",
    "            if len(packets) > 0 :\n",
    "                latestPacket[queueName] = packets[-1]\n",
    "        data_image          = np.zeros((55,3)) # Contain x y with 1280x720 resolution and z in metre.\n",
    "        data_norm_image     = np.zeros((55,3)) # Contain normalized x y in range (0,1) and z in metre.\n",
    "        data_world          = np.zeros((55,3)) # Contain x y and z in metre.\n",
    "        #---- RGB ----#\n",
    "        if latestPacket[\"rgb\"] is not None:\n",
    "            rgbFrame = latestPacket[\"rgb\"].getCvFrame()\n",
    "            # Pre-process\n",
    "            rgbFrame.flags.writeable = False\n",
    "            rgbFrame = cv2.cvtColor(rgbFrame, cv2.COLOR_BGR2RGB)\n",
    "            # Note that handedness is determined assuming the input image is mirrored, \n",
    "            # i.e., taken with a front-facing/selfie camera with images flipped horizontally. \n",
    "            # If it is not the case, please swap the handedness output in the application.\n",
    "            rgbFrame = cv2.flip(rgbFrame, 1)\n",
    "            hand_results = hands.process(rgbFrame)\n",
    "            pose_results = pose.process(rgbFrame)\n",
    "            # Draw the hand annotations on the image.\n",
    "            rgbFrame.flags.writeable = True\n",
    "            rgbFrame = cv2.cvtColor(rgbFrame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #--- Depth ---#\n",
    "            if latestPacket[\"depth\"] is not None:\n",
    "                depthFrame = latestPacket[\"depth\"].getCvFrame()\n",
    "                depthFrame = cv2.flip(depthFrame, 1)\n",
    "                # Get disparity frame for nicer depth visualization\n",
    "                if latestPacket[\"disp\"] is not None:\n",
    "                    dispFrame = latestPacket[\"disp\"].getFrame()\n",
    "                    maxDisparity = stereo.initialConfig.getMaxDisparity()\n",
    "\n",
    "                \n",
    "                    dispFrame = (dispFrame * (255 / maxDisparity)).astype(np.uint8)\n",
    "                    dispFrame = cv2.applyColorMap(dispFrame, cv2.COLORMAP_JET)\n",
    "                    dispFrame = np.ascontiguousarray(dispFrame)\n",
    "                    dispFrame = cv2.flip(dispFrame, 1)\n",
    "                    if hand_results.multi_hand_landmarks:\n",
    "                        for index, hand in enumerate(hand_results.multi_hand_landmarks) :\n",
    "                            # Draw hand on RGB Frame\n",
    "                            mp_drawing.draw_landmarks(  rgbFrame,\n",
    "                                                        hand,\n",
    "                                                        mp_hands.HAND_CONNECTIONS,\n",
    "                                                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                                        mp_drawing_styles.get_default_hand_connections_style())\n",
    "                            # Draw hand on Depth Frame\n",
    "                            mp_drawing.draw_landmarks(  dispFrame,\n",
    "                                                        hand,\n",
    "                                                        mp_hands.HAND_CONNECTIONS,\n",
    "                                                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                                        mp_drawing_styles.get_default_hand_connections_style())\n",
    "                            # get points of each hand\n",
    "                            Label,hand_points,hand_norm_points = get_hand_data(index,hand,hand_results)\n",
    "                            if Label == 'Left' : \n",
    "                                data_image[0:21,:] = hand_points\n",
    "                                data_norm_image[0:21,:] = hand_norm_points\n",
    "                            else :\n",
    "                                data_image[21:42,:] = hand_points\n",
    "                                data_norm_image[21:42,:] = hand_norm_points\n",
    "                    if pose_results.pose_landmarks : \n",
    "                        # Draw Pose on RGB Frame\n",
    "                        mp_drawing.draw_landmarks(  rgbFrame,\n",
    "                                                    pose_results.pose_landmarks,\n",
    "                                                    mp_pose.POSE_CONNECTIONS,\n",
    "                                                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                        # Draw Pose on Depth Frame\n",
    "                        mp_drawing.draw_landmarks(  dispFrame,\n",
    "                                                    pose_results.pose_landmarks,\n",
    "                                                    mp_pose.POSE_CONNECTIONS,\n",
    "                                                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                        # get points of pose\n",
    "                        pose_points,pose_norm_points = get_pose_data(pose_results)\n",
    "                        data_image[42:55,:] = pose_points\n",
    "                        data_norm_image[42:55,:] = pose_norm_points\n",
    "                    for i in range(55) : \n",
    "                        x = int(data_image[i,0])\n",
    "                        y = int(data_image[i,1]) \n",
    "                        spatials, centroid = get_spatial(depthFrame,x,y)\n",
    "                        if not math.isnan(float(spatials['x']))  : data_world[i,0] = spatials['x']/1000\n",
    "                        if not math.isnan(float(spatials['y']))  : data_world[i,1] = spatials['y']/1000\n",
    "                        if not math.isnan(float(spatials['z']))  : \n",
    "                            data_world[i,2]    = spatials['z']/1000\n",
    "                            data_norm_image[i,2] = spatials['z']/1000\n",
    "                            data_image[i,2]      = spatials['z']/1000\n",
    "                        if DisplayRect : text.rectangle(dispFrame, (x-delta, y-delta), (x+delta, y+delta))\n",
    "                    image_sequence.append(data_image)\n",
    "                    norm_image_sequence.append(data_norm_image)\n",
    "                    world_sequence.append(data_world)\n",
    "                    # Calculate FPS\n",
    "                    currentTime = time.time()\n",
    "                    fps = 1 / (currentTime-previousTime)\n",
    "                    previousTime = currentTime\n",
    "                    # Display FPS on the image\n",
    "                    cv2.putText(rgbFrame, f\" FPS : {int(fps)}\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                    cv2.putText(dispFrame, f\" FPS : {int(fps)}\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "            \n",
    "                    # Display the resulting image\n",
    "                    cv2.imshow(rgbWindowName, rgbFrame)\n",
    "                    if Show_depth : cv2.imshow(depthWindowName, dispFrame)\n",
    "                    rgbFrame = None\n",
    "                    depthFrame = None\n",
    "                    dispFrame = None\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b9221c9fa0c804214309051805ad5497afac26eb3bf5b138d56a6216387e02b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
